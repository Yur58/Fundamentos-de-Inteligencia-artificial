{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtvR9lF5Y8CSH8gdyTZB0g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yur58/Fundamentos-de-Inteligencia-artificial/blob/main/EXTRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdfdeVgOxLlS",
        "outputId": "152740ab-31c5-4f8a-b2e0-0c638467ce1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.8.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "_random_state = 40\n",
        "# Obtener el dataset de hongos\n",
        "hongo = fetch_ucirepo(id=73)\n",
        "\n",
        "# Datos\n",
        "X = hongo.data.features\n",
        "y = hongo.data.targets.iloc[:, 0]  # tomar la única columna del target\n",
        "\n",
        "# Convertir variables categóricas a numéricas (one-hot encoding)\n",
        "X_encoded = pd.get_dummies(X)\n",
        "\n",
        "print(\"Shape original:\", X.shape)\n",
        "print(\"Shape codificado:\", X_encoded.shape)\n",
        "\n",
        "#################################\n",
        "# Caso A: Logistic Regression\n",
        "\n",
        "X_train_A, X_test_A, y_train_A, y_test_A = train_test_split(\n",
        "    X_encoded,  # usamos los datos codificados\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=_random_state,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "model_A = LogisticRegression(max_iter=200)\n",
        "model_A.fit(X_train_A, y_train_A)\n",
        "\n",
        "y_pred_A = model_A.predict(X_test_A)\n",
        "\n",
        "# Métricas\n",
        "acc_A = accuracy_score(y_test_A, y_pred_A)\n",
        "prec_A = precision_score(y_test_A, y_pred_A, average='weighted')\n",
        "rec_A = recall_score(y_test_A, y_pred_A, average='weighted')\n",
        "f1_A = f1_score(y_test_A, y_pred_A, average='weighted')\n",
        "\n",
        "cm_A = confusion_matrix(y_test_A, y_pred_A)\n",
        "cm_df_A = pd.DataFrame(cm_A, index=sorted(y.unique()), columns=sorted(y.unique()))\n",
        "\n",
        "print(\"-\"*30)\n",
        "print(\"CASO A: Logistic Regression\")\n",
        "print(\"Accuracy:\", acc_A)\n",
        "print(\"Precision (ponderada):\", prec_A)\n",
        "print(\"Recall (ponderado):\", rec_A)\n",
        "print(\"F1-score (ponderado):\", f1_A)\n",
        "print(\"\\nMatriz de confusión:\")\n",
        "print(cm_df_A)\n",
        "print(\"\")\n",
        "\n",
        "#################################\n",
        "# Caso B: Random Forest\n",
        "\n",
        "X_train_B, X_test_B, y_train_B, y_test_B = train_test_split(\n",
        "    X_encoded,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=_random_state,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "model_B = RandomForestClassifier(random_state=_random_state)\n",
        "model_B.fit(X_train_B, y_train_B)\n",
        "\n",
        "y_pred_B = model_B.predict(X_test_B)\n",
        "\n",
        "# Métricas\n",
        "acc_B = accuracy_score(y_test_B, y_pred_B)\n",
        "prec_B = precision_score(y_test_B, y_pred_B, average='weighted')\n",
        "rec_B = recall_score(y_test_B, y_pred_B, average='weighted')\n",
        "f1_B = f1_score(y_test_B, y_pred_B, average='weighted')\n",
        "\n",
        "cm_B = confusion_matrix(y_test_B, y_pred_B)\n",
        "cm_df_B = pd.DataFrame(cm_B, index=sorted(y.unique()), columns=sorted(y.unique()))\n",
        "\n",
        "print(\"-\"*30)\n",
        "print(\"CASO B: Random Forest Classifier\")\n",
        "print(\"Accuracy:\", acc_B)\n",
        "print(\"Precision (ponderada):\", prec_B)\n",
        "print(\"Recall (ponderado):\", rec_B)\n",
        "print(\"F1-score (ponderado):\", f1_B)\n",
        "print(\"\\nMatriz de confusión:\")\n",
        "print(cm_df_B)\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-eoAM1Xw-5X",
        "outputId": "4bbda484-29f7-43ee-f922-77e09d091a5b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape original: (8124, 22)\n",
            "Shape codificado: (8124, 116)\n",
            "------------------------------\n",
            "CASO A: Logistic Regression\n",
            "Accuracy: 1.0\n",
            "Precision (ponderada): 1.0\n",
            "Recall (ponderado): 1.0\n",
            "F1-score (ponderado): 1.0\n",
            "\n",
            "Matriz de confusión:\n",
            "     e    p\n",
            "e  842    0\n",
            "p    0  783\n",
            "\n",
            "------------------------------\n",
            "CASO B: Random Forest Classifier\n",
            "Accuracy: 1.0\n",
            "Precision (ponderada): 1.0\n",
            "Recall (ponderado): 1.0\n",
            "F1-score (ponderado): 1.0\n",
            "\n",
            "Matriz de confusión:\n",
            "     e    p\n",
            "e  842    0\n",
            "p    0  783\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
